#include "lai_regress.h"
#include "cstring"
#include <limits>
#include <cmath>
#include "t_distribution.hpp"
#include <immintrin.h>
#include <cblas.h>
#include <chrono>

using hires_clock = std::chrono::high_resolution_clock;

using std::cout; using std::endl; using std::ifstream;
using std::string; using std::getline;

extern "C" {
    void dpotrf_(char* uplo, int* n, double* A, int* lda, int* info);
    void dpotrs_(char* uplo, int* n, int* nrhs, double* A, int* lda, double* B, int* ldb, int* info);
    void dpotri_(char* uplo, int* n, double* A, int* lda, int* info);
}

// avx2 vectorized logistic function generated by Sonnet 4.5
__m256d exp_avx2(__m256d x) {
    // Constants
    __m256d log2e = _mm256_set1_pd(1.4426950408889634073599);  // 1/ln(2)
    __m256d ln2_hi = _mm256_set1_pd(0.693145751953125);
    __m256d ln2_lo = _mm256_set1_pd(1.42860682030941723212e-6);
    
    // Polynomial coefficients for exp(r) where r is in [-ln(2)/2, ln(2)/2]
    __m256d c1 = _mm256_set1_pd(1.0);
    __m256d c2 = _mm256_set1_pd(0.5);
    __m256d c3 = _mm256_set1_pd(0.166666666666666019037);
    __m256d c4 = _mm256_set1_pd(0.0416666666666666019037);
    __m256d c5 = _mm256_set1_pd(0.00833333333333333019037);
    __m256d c6 = _mm256_set1_pd(0.00138888888888888894107);
    __m256d c7 = _mm256_set1_pd(0.000198412698412698412698);
    __m256d c8 = _mm256_set1_pd(0.0000248015873015873015873);
    
    // Clamp input to prevent overflow/underflow
    __m256d max_input = _mm256_set1_pd(709.0);
    __m256d min_input = _mm256_set1_pd(-709.0);
    x = _mm256_min_pd(x, max_input);
    x = _mm256_max_pd(x, min_input);
    
    // Convert to base 2: z = x * log2(e)
    __m256d z = _mm256_mul_pd(x, log2e);
    
    // Get integer part (exponent)
    __m256d n = _mm256_round_pd(z, _MM_FROUND_TO_NEAREST_INT);
    
    // Get fractional part: r = x - n*ln(2)
    // Use high and low parts for better accuracy
    __m256d r = _mm256_sub_pd(x, _mm256_mul_pd(n, ln2_hi));
    r = _mm256_sub_pd(r, _mm256_mul_pd(n, ln2_lo));
    
    // Compute polynomial approximation using Horner's method
    // exp(r) ≈ 1 + r + r²/2! + r³/3! + ... + r^8/8!
    __m256d poly = c8;
    poly = _mm256_fmadd_pd(poly, r, c7);
    poly = _mm256_fmadd_pd(poly, r, c6);
    poly = _mm256_fmadd_pd(poly, r, c5);
    poly = _mm256_fmadd_pd(poly, r, c4);
    poly = _mm256_fmadd_pd(poly, r, c3);
    poly = _mm256_fmadd_pd(poly, r, c2);
    poly = _mm256_fmadd_pd(poly, r, c1);
    poly = _mm256_fmadd_pd(poly, r, c1);
    
    // Scale by 2^n using integer manipulation
    __m128i ni_low = _mm256_cvtpd_epi32(n);  // Convert to 32-bit integers
    __m256i ni = _mm256_cvtepi32_epi64(ni_low);  // Extend to 64-bit
    __m256i exp_bias = _mm256_set1_epi64x(1023LL);
    ni = _mm256_add_epi64(ni, exp_bias);
    ni = _mm256_slli_epi64(ni, 52);  // Shift to exponent position in double
    __m256d scale = _mm256_castsi256_pd(ni);
    
    // Final result: exp(x) = exp(r) * 2^n
    return _mm256_mul_pd(poly, scale);
}

// AVX2 logistic (sigmoid) function: σ(x) = 1 / (1 + exp(-x))
__m256d logistic_avx2(__m256d x) {
    // Negate input: -x
    __m256d neg_x = _mm256_sub_pd(_mm256_setzero_pd(), x);

    // Compute exp(-x)
    __m256d exp_neg_x = exp_avx2(neg_x);

    // Compute 1 + exp(-x)
    __m256d one = _mm256_set1_pd(1.0);
    __m256d denominator = _mm256_add_pd(one, exp_neg_x);

    // Compute 1 / (1 + exp(-x))
    return _mm256_div_pd(one, denominator);
}

__m256d logistic_stable_avx2(__m256d x) {
    __m256d zero = _mm256_setzero_pd();
    __m256d one = _mm256_set1_pd(1.0);

    // For x >= 0: σ(x) = 1 / (1 + exp(-x))
    // For x < 0:  σ(x) = exp(x) / (1 + exp(x))

    __m256d mask = _mm256_cmp_pd(x, zero, _CMP_GE_OQ);

    // Compute positive branch: 1 / (1 + exp(-x))
    __m256d neg_x = _mm256_sub_pd(zero, x);
    __m256d exp_neg_x = exp_avx2(neg_x);
    __m256d pos_result = _mm256_div_pd(one, _mm256_add_pd(one, exp_neg_x));

    // Compute negative branch: exp(x) / (1 + exp(x))
    __m256d exp_x = exp_avx2(x);
    __m256d neg_result = _mm256_div_pd(exp_x, _mm256_add_pd(one, exp_x));

    // Select based on sign
    return _mm256_blendv_pd(neg_result, pos_result, mask);
}

void logistic_avx2(double* eta, double *mu, int n) {
    int i;
    // Process 4 elements at a time (AVX2 handles 4 doubles)
    for (i = 0; i <= n - 4; i += 4) {
        __m256d x = _mm256_loadu_pd(&eta[i]);
        __m256d result = logistic_stable_avx2(x);
        _mm256_storeu_pd(&mu[i], result);
    }

    // Handle remaining elements
    for (; i < n; i++) {
       mu[i] = 1.0 / (1.0 + exp(-eta[i]));
    }
}

void matvec_colmajor_avx2(double* A, double* x, double* y, int N, int p) {

    int i, j;

    // Process 4 rows at a time
    int block = 4;
    for (j = 0; j < p; ++j) {            // Loop over columns
        __m256d xj = _mm256_set1_pd(x[j]); // Broadcast x[j] to all lanes

        // Loop over rows
        for (i = 0; i + block - 1 < N; i += block) {
            __m256d yv = _mm256_loadu_pd(y + i);       // Load 4 rows
            __m256d av = _mm256_loadu_pd(A + j*N + i); // Load 4 elements from column j
            yv = _mm256_fmadd_pd(av, xj, yv);          // yv += av * xj
            _mm256_storeu_pd(y + i, yv);               // Store back
        }

        // Handle remaining rows if N % 4 != 0
        for (; i < N; ++i) {
            y[i] += A[j*N + i] * x[j];
        }
    }
}

// blas is faster than avx2 generated by chatgpt
void compute_XTWX_blas(double *X, double *W, double *result, int n, int p) {
    // Create W^(1/2) * X in-place or in temp array
    double *WX = (double *) malloc(n * p * sizeof(double));

    // Scale each row i by sqrt(W[i])
    for (int j = 0; j < p; j++) {
        for (int i = 0; i < n; i++) {
            WX[j * n + i] = sqrt(W[i]) * X[j * n + i];
        }
    }

    // Compute (W^(1/2)X)^T * (W^(1/2)X) = X^T W X
    cblas_dsyrk(CblasColMajor, CblasUpper, CblasTrans,
                p, n, 1.0, WX, n, 0.0, result, p);

    free(WX);
}

void XtWz_AVX2(const double* X, const double* w, const double* z,
               size_t n, size_t p, double* XtWz)
{
    for (size_t j = 0; j < p; ++j) {
        __m256d acc = _mm256_setzero_pd();
        size_t i = 0;

        for (; i + 3 < n; i += 4) {
            __m256d Xij = _mm256_loadu_pd(&X[j*n + i]);
            __m256d wv  = _mm256_loadu_pd(&w[i]);
            __m256d zv  = _mm256_loadu_pd(&z[i]);
            acc = _mm256_fmadd_pd(Xij, _mm256_mul_pd(wv, zv), acc);
        }

        double tmp[4];
        _mm256_storeu_pd(tmp, acc);
        XtWz[j] = tmp[0] + tmp[1] + tmp[2] + tmp[3];

        for (; i < n; ++i)
            XtWz[j] += X[j*n + i] * w[i] * z[i];
    }
}

/*void XtWz_BLAS(const double* X,
               const double* w,
               const double* z,
               size_t n,
               size_t p,
               double* XtWz)
{
    // Allocate temporary buffer for w ⊙ z
    double* wz = (double*)malloc(n * sizeof(double));
    if (!wz) return;  // allocation failed

    // Compute elementwise product wz = w * z
    // Vectorized elementwise product
    size_t i = 0;
    for (; i + 3 < n; i += 4) {
        __m256d wv = _mm256_loadu_pd(&w[i]);
        __m256d zv = _mm256_loadu_pd(&z[i]);
        _mm256_storeu_pd(&wz[i], _mm256_mul_pd(wv, zv));
    }
    for (; i < n; ++i)
        wz[i] = w[i] * z[i];

    // Compute XtWz = X^T * wz using BLAS
    cblas_dgemv(CblasColMajor,  // X is column-major
                CblasTrans,     // want X^T
                (int)n,
                (int)p,
                1.0,            // alpha
                X,
                (int)n,         // leading dimension
                wz,
                1,              // stride of wz
                0.0,            // beta
                XtWz,
                1);             // stride of XtWz
    free(wz);
}*/

void solveXtWXbeta(double* XtWX, double* XtWz, size_t p) {
    int info;
    char uplo = 'U';
    int n = p;
    int nrhs = 1;

    // Cholesky factorization: A = U^T U
    dpotrf_(&uplo, &n, XtWX, &n, &info);
    if (info != 0) {
	// Matrix not positive definite
        cout << "XtWX is not positive definite!" << endl;
    }

    // Solve A * beta = B
    dpotrs_(&uplo, &n, &nrhs, XtWX, &n, XtWz, &n, &info);
}

void invert_XtWX(double* XtWX, int p) {
    int info;
    char uplo = 'U'; // use upper triangular

    // Step 2: Invert from Cholesky factor
    dpotri_(&uplo, &p, XtWX, &p, &info);
}

void fit_cov(Dat *dat) {
    int n = dat->n_ind;
    int p = dat->n_cov;

    int max_iter = 25;

    double *eta = (double *) calloc(n, sizeof(double));
    double *mu = (double *) calloc(n, sizeof(double));
    double *W = (double *) calloc(n, sizeof(double));
    double *z = (double *) calloc(n, sizeof(double));
    double *alpha = (double *) calloc(p+2, sizeof(double));
    double *XtWX = (double *) calloc((p+2)*(p+2), sizeof(double));
    double *XtWz = (double *) calloc(p+2, sizeof(double));

    // for later use
    dat->X = (double *) calloc(n*(p+2), sizeof(double));
    memcpy(dat->X, dat->W, n*p*sizeof(double));

    for (int iter = 0; iter < max_iter; ++iter) {
    
	// eta = W \alpha
	matvec_colmajor_avx2(dat->W, alpha, eta, n, p);

	// mu = 1 / (1 + exp(-\eta))
	logistic_avx2(eta, mu, n);

	// W 
	for (size_t i=0; i<n; i++) {
	    W[i] = mu[i] * (1 - mu[i]);
	}
	
	// z = (Y - mu) / mu (1 - mu)
	for (size_t i=0; i<n; i++) {
	    z[i] = eta[i] + (dat->pheno[i] - mu[i]) / W[i];
	}
	
	// XtWX
	compute_XTWX_blas(dat->W, W, XtWX, n, p);

	// XtW z
	XtWz_AVX2(dat->W, W, z, n, p, XtWz);
	
	// solve for alpha
	solveXtWXbeta(XtWX, XtWz, p);

	double max_diff = 0, diff = 0;
	for (size_t i = 0; i < p; ++i) {
            diff = std::fabs(XtWz[i] - alpha[i]);
	    if (diff > max_diff) {
                max_diff = diff;
	    }
	    alpha[i] = XtWz[i];
	}
	
	if (max_diff < 1e-6) {
	    /*cout <<  iter + 1 << endl;
	    cout << alpha[0] << endl;
	    cout << alpha[1] << endl;
	    double se_j = 0;
	    invert_XtWX(XtWX, p);
	    for (int j = 0; j < p; ++j) {
		se_j = sqrt(XtWX[j*p + j]); 
	    }*/
	    
	    memset(eta, 0, n*sizeof(double));
	    memset(mu, 0, n*sizeof(double));
	    memset(XtWX, 0, p*p*sizeof(double));
	    memset(XtWz, 0, p*sizeof(double));
	    dat->beta = alpha;
	    dat->eta = eta;
	    dat->mu = mu;
	    dat->z = z;
            dat->weight = W;
            dat->XtWX = XtWX;
            dat->XtWz = XtWz;
	    break;
	}
	memset(eta, 0, n*sizeof(double));
	memset(mu, 0, n*sizeof(double));
	memset(XtWX, 0, p*p*sizeof(double));
	memset(XtWz, 0, p*sizeof(double));
    }
}

void logistic(Dat *dat, double *X) {
    int n = dat->n_ind;
    int p = dat->n_cov;

    // check mac
    int mac1 = 0, mac2 = 0;
    for (size_t i=0; i<n; i++) {
	mac1 += X[i];
    }
    for (size_t i=0; i<n; i++) {
        mac2 += X[n+i];
    }
    
    if (mac1 > n / 2) {
        mac1 = n - mac1;
    }

    if (mac1 > n / 2) {
        mac2 = n - mac2;
    }

    if (mac1 >= 400 && mac2 >= 400) {
        memcpy(&dat->X[n*p], X, n*2*sizeof(double));
	p += 2;
    }
    else if (mac1 < 400 && mac2 >= 400) {
	memcpy(&dat->X[n*p], &X[n], n*sizeof(double));
	p += 1;
    }
    else if (mac1 >= 400 && mac2 < 400) {
	memcpy(&dat->X[n*p], X, n*sizeof(double));
	p += 1;
    }	
    else {
	dat->mac1.push_back(0);
	dat->mac2.push_back(0);
    	dat->beta1.push_back(std::numeric_limits<double>::quiet_NaN());
	dat->beta2.push_back(std::numeric_limits<double>::quiet_NaN());
	dat->se1.push_back(std::numeric_limits<double>::quiet_NaN());
	dat->se2.push_back(std::numeric_limits<double>::quiet_NaN());
	dat->p1.push_back(std::numeric_limits<double>::quiet_NaN());
	dat->p2.push_back(std::numeric_limits<double>::quiet_NaN());
	dat->se_diff.push_back(std::numeric_limits<double>::quiet_NaN());
	dat->p_diff.push_back(std::numeric_limits<double>::quiet_NaN());
	return;
    }

    int max_iter = 25;

    double se1 = 0, se2 = 0;
    double p1 = 0, p2 = 0;
    double z1 = 0, z2 = 0;
    double diff = 0, se_diff = 0, p_diff = 0;

    for (int iter = 0; iter < max_iter; ++iter) {
    
	// eta = W \alpha
	matvec_colmajor_avx2(dat->X, dat->beta, dat->eta, n, p);

	// mu = 1 / (1 + exp(-\eta))
	logistic_avx2(dat->eta, dat->mu, n);

	// W 
	for (size_t i=0; i<n; i++) {
	    dat->weight[i] = dat->mu[i] * (1 - dat->mu[i]);
	}
	
	// z = (Y - mu) / mu (1 - mu)
	for (size_t i=0; i<n; i++) {
	    dat->z[i] = dat->eta[i] + (dat->pheno[i] - dat->mu[i]) / dat->weight[i];
	}

	// XtWX
	compute_XTWX_blas(dat->X, dat->weight, dat->XtWX, n, p);

	// XtW z
	XtWz_AVX2(dat->X, dat->weight, dat->z, n, p, dat->XtWz);
	
	// solve for alpha
	solveXtWXbeta(dat->XtWX, dat->XtWz, p);

	double max_diff = 0, diff = 0;
	for (size_t i = 0; i < p; ++i) {
            diff = std::fabs(dat->XtWz[i] - dat->beta[i]);
	    if (diff > max_diff) {
                max_diff = diff;
	    }
	    dat->beta[i] = dat->XtWz[i];
	}
	
	if (max_diff < 1e-6 || iter == (max_iter-1)) {
	    /*cout <<  iter + 1 << endl;
	    cout << dat->beta[0] << endl;
	    cout << dat->beta[p-2] << endl;
	    cout << dat->beta[p-1] << endl;*/
	    invert_XtWX(dat->XtWX, p);
	    
	    // write to the output
	    if (mac1 >= 400 && mac2 >= 400) {
		se1 = sqrt(dat->XtWX[(p-2)*p + p-2]);
                z1 = dat->beta[p-2] / se1;
		se2 = sqrt(dat->XtWX[(p-1)*p + p-1]);
		z2 = dat->beta[p-1] / se2;
		se_diff = sqrt(dat->XtWX[(p-2)*p + p-2] + dat->XtWX[(p-1)*p + p-1] - 2*dat->XtWX[p*p-2]);
		diff = (dat->beta[p-1] - dat->beta[p-2]) / se_diff;
		p1 = t_distribution::chi2_pvalue(z1*z1, 1);
		p2 = t_distribution::chi2_pvalue(z2*z2, 1);
		p_diff = t_distribution::chi2_pvalue(diff*diff, 1);
		dat->beta1.push_back(dat->beta[p-2]);
		dat->beta2.push_back(dat->beta[p-1]);
	    }
	    else if (mac1 < 400 && mac2 >= 400) {
		se1 = std::numeric_limits<double>::quiet_NaN();
                z1 = std::numeric_limits<double>::quiet_NaN();
                se2 = sqrt(dat->XtWX[(p-1)*p + p-1]);
                z2 = dat->beta[p-1] / se2;
                se_diff = std::numeric_limits<double>::quiet_NaN();
                diff = std::numeric_limits<double>::quiet_NaN();
                p1 = std::numeric_limits<double>::quiet_NaN();
                p2 = t_distribution::chi2_pvalue(z2*z2, 1);
                p_diff = std::numeric_limits<double>::quiet_NaN();
		dat->beta1.push_back(std::numeric_limits<double>::quiet_NaN());
		dat->beta2.push_back(dat->beta[p-1]);
	    }
	    else if (mac1 >= 400 && mac2 < 400) {
		se1 = sqrt(dat->XtWX[(p-1)*p + p-1]);
                z1 = dat->beta[p-1] / se1;
                se2 = std::numeric_limits<double>::quiet_NaN();
                z2 = std::numeric_limits<double>::quiet_NaN();
                se_diff = std::numeric_limits<double>::quiet_NaN();
                diff = std::numeric_limits<double>::quiet_NaN();
                p1 = t_distribution::chi2_pvalue(z1*z1, 1);
                p2 = std::numeric_limits<double>::quiet_NaN();
                p_diff = std::numeric_limits<double>::quiet_NaN();
		dat->beta1.push_back(dat->beta[p-1]);
		dat->beta2.push_back(std::numeric_limits<double>::quiet_NaN());
	    }
	     
	    dat->mac1.push_back(mac1);
	    dat->mac2.push_back(mac2);
	    dat->se1.push_back(se1);
	    dat->se2.push_back(se2);
	    dat->p1.push_back(p1);
	    dat->p2.push_back(p2);
	    dat->se_diff.push_back(se_diff);
	    dat->p_diff.push_back(p_diff);
	    
	    memset(dat->eta, 0, n*sizeof(double));
	    memset(dat->mu, 0, n*sizeof(double));
	    memset(dat->XtWX, 0, p*p*sizeof(double));
	    memset(dat->XtWz, 0, p*sizeof(double));
	    dat->beta[p-2] = 0;
	    dat->beta[p-1] = 0;
	    break;
	}
	memset(dat->eta, 0, n*sizeof(double));
	memset(dat->mu, 0, n*sizeof(double));
	memset(dat->XtWX, 0, p*p*sizeof(double));
	memset(dat->XtWz, 0, p*sizeof(double));
    }
}
